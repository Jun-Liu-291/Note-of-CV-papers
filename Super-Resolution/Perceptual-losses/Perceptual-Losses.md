# Perceptual Losses for Real-Time Style Transfer and Super-Resolution

2020-01-04
https://arxiv.org/pdf/1603.08155.pdf

## Abstract
  * Consider image transformation problems, where an input image is transformed into an output image.
  * Recent methods for such problems typically train feed-forward CNN using a per-pixel loss between the output and ground truth images.
  * Parallel work has shown that high-quality images can be generated by defining and optimizing *perceptual* loss functions based on high-level features extracted from pretrained networks.
  
## Introduction
  * Example: denoising, super-resolution and colorization. from computer vision include semantic segmentation and depth estimation.
  * One approach for solving image transformation tasks is to train a feed-forward CNN in a supervised manner, using a per-pixel loss function to measure the difference between output and ground-truth images, such approaches are efficient at test-time, requiring only a forward pass through the trained network.
  * While, this per-pixel loss function do not capture *percepual* differences between output and ground-truth images.
