# Perceptual Losses for Real-Time Style Transfer and Super-Resolution

2020-01-04
https://arxiv.org/pdf/1603.08155.pdf

## Abstract
  * Consider image transformation problems, where an input image is transformed into an output image.
  * Recent methods for such problems typically train feed-forward CNN using a per-pixel loss between the output and ground truth images.
  * Parallel work has shown that high-quality images can be generated by defining and optimizing *perceptual* loss functions based on high-level features extracted from pretrained networks.
  
## 1. Introduction
  * Example: denoising, super-resolution and colorization. from computer vision include semantic segmentation and depth estimation.
  * One approach for solving image transformation tasks is to train a feed-forward CNN in a supervised manner, using a per-pixel loss function to measure the difference between output and ground-truth images, such approaches are efficient at test-time, requiring only a forward pass through the trained network.
  * While, this per-pixel loss function do not capture *percepual* differences between output and ground-truth images.
  * Combine the benefits of these two approaches.:
   ** Train feed-forward *transformation networks* for image transformation tasks
   ** Train networks using *perceptual loss functions* that depend on high-level features from a pretrained *loss netowrk*
   ** During training, perceptual losses measure image similarities more robustly than per-pixel losses, and at test-time the transformation networks run in real-time.

## 2. Related Workd
### Feed-forward image transformation
 * Semantic segmentation methods
 * Depth and surface normal estimation
### Perceptual optimization
 * Images can be generated to maximize class prediction scores or individual features in order to understand the functions encoded in trained networks.
### Style Transfer
### Image super-resolution

## 3. Method
 * Components:</br>
  ** image transformation network fw: a deep residual CNN
  ** loss network φ used to define several loss functions.
 * Inshight of these methods is that CNN pretrained for image classification have already learned to encode the perceptual and semantic information we would like to measure in our loss functions.
 * The loss network φ is used to define a feature reconstruction loss and a style reconstruction loss that measure differences in content and style between images.
